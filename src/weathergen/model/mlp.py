# (C) Copyright 2025 WeatherGenerator contributors.
#
# This software is licensed under the terms of the Apache Licence Version 2.0
# which can be obtained at http://www.apache.org/licenses/LICENSE-2.0.
#
# In applying this licence, ECMWF does not waive the privileges and immunities
# granted to it by virtue of its status as an intergovernmental organisation
# nor does it submit to any jurisdiction.

import torch
from weathergen.model.norms import RMSNorm
from weathergen.model.norms import AdaLayerNorm

class MLP( torch.nn.Module) :

  def __init__(self, dim_in, dim_out, num_layers = 2, hidden_factor = 2, 
                     pre_layer_norm = True, dropout_rate = 0., nonlin = torch.nn.GELU,
                     with_residual = False, norm_type = 'LayerNorm', dim_aux=None) :
    '''Constructor'''
 
    super( MLP, self).__init__()

    assert num_layers >= 2

    self.with_residual = with_residual
    self.with_aux = dim_aux is not None
    dim_hidden = int( dim_in * hidden_factor)

    self.layers = torch.nn.ModuleList()

    norm = torch.nn.LayerNorm if norm_type=='LayerNorm' else RMSNorm

    if pre_layer_norm :
      self.layers.append( norm( dim_in) if dim_aux is None else AdaLayerNorm( dim_in, dim_aux))

    self.layers.append( torch.nn.Linear( dim_in, dim_hidden))
    self.layers.append( nonlin())
    self.layers.append( torch.nn.Dropout( p = dropout_rate))

    for il in range(num_layers-2) :
      self.layers.append( torch.nn.Linear( dim_hidden, dim_hidden))
      self.layers.append( nonlin())
      self.layers.append( torch.nn.Dropout( p = dropout_rate))
    
    self.layers.append( torch.nn.Linear( dim_hidden, dim_out))
    self.layers.append( nonlin())

  def forward( self, *args) :

    x, x_in, aux = args[0], args[0], args[-1]

    for i,layer in enumerate(self.layers) :
      x = layer( x, aux) if (i==0 and self.with_aux) else layer( x)

    if self.with_residual :
      if x.shape[-1] == x_in.shape[-1] :
        x = x_in + x
      else :
        assert x.shape[-1] % x_in.shape[-1] == 0
        x = x + x_in.repeat([ *[1 for _ in x.shape[:-1]], x.shape[-1] // x_in.shape[-1] ])

    return x


